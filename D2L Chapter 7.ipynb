{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOdAyjGw4BfYiWwcHvi8QeL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!python -m pip install --upgrade pip\n","!pip3 uninstall d2l -y\n","!pip3 uninstall tensorflow -y\n","!pip3 uninstall numpy -y\n","!pip3 uninstall matplotlib -y\n","!pip3 install d2l\n","!pip3 install tensorflow\n","!pip3 install pandas==1.3.5\n","!pip3 install matplotlib\n","!pip3 install --upgrade pandas"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ObDUwElDOZzx","executionInfo":{"status":"ok","timestamp":1683887262344,"user_tz":-540,"elapsed":94290,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"outputId":"e17db50a-1093-4e29-c410-22270f39585b"},"execution_count":168,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Found existing installation: d2l 0.17.6\n","Uninstalling d2l-0.17.6:\n","  Successfully uninstalled d2l-0.17.6\n","Found existing installation: tensorflow 2.12.0\n","Uninstalling tensorflow-2.12.0:\n","  Successfully uninstalled tensorflow-2.12.0\n","Found existing installation: numpy 1.23.5\n","Uninstalling numpy-1.23.5:\n","  Successfully uninstalled numpy-1.23.5\n","Found existing installation: matplotlib 3.5.1\n","Uninstalling matplotlib-3.5.1:\n","  Successfully uninstalled matplotlib-3.5.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting d2l\n","  Using cached d2l-0.17.6-py3-none-any.whl (112 kB)\n","Requirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.10/dist-packages (from d2l) (1.0.0)\n","Collecting numpy==1.21.5 (from d2l)\n","  Using cached numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","Collecting matplotlib==3.5.1 (from d2l)\n","  Using cached matplotlib-3.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.9 MB)\n","Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.10/dist-packages (from d2l) (2.25.1)\n","Collecting pandas==1.2.4 (from d2l)\n","  Using cached pandas-1.2.4-cp310-cp310-linux_x86_64.whl\n","Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.4.8)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.4.3)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.1.0)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (6.5.4)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (5.5.6)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l) (7.7.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.5.1->d2l) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.2.4->d2l) (2022.7.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->d2l) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->d2l) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->d2l) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.25.1->d2l) (2022.12.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.5.1->d2l) (1.16.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (7.34.0)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.7.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (6.2)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.6.4)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.7)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.38)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.14.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.9.2)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.11.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (6.0.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.4)\n","Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.2)\n","Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.3.0)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.2)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.4)\n","Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (5.8.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.2.1)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (23.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (21.3.0)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.5.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.17.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.16.0)\n","Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.3.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (67.7.2)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.18.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l) (3.3.0)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (2.16.3)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (4.3.3)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l) (0.2.6)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l) (21.2.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.4.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (23.1.0)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l) (0.19.3)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l) (2.21)\n","Installing collected packages: numpy, pandas, matplotlib, d2l\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.3.5\n","    Uninstalling pandas-1.3.5:\n","      Successfully uninstalled pandas-1.3.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.0.6 requires tensorflow>=2.2.0, which is not installed.\n","arviz 0.15.1 requires pandas>=1.3.0, but you have pandas 1.2.4 which is incompatible.\n","google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 1.2.4 which is incompatible.\n","google-colab 1.0.0 requires requests>=2.27.0, but you have requests 2.25.1 which is incompatible.\n","mizani 0.8.1 requires pandas>=1.3.5, but you have pandas 1.2.4 which is incompatible.\n","plotnine 0.10.1 requires pandas>=1.3.5, but you have pandas 1.2.4 which is incompatible.\n","xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.2.4 which is incompatible.\n","yfinance 0.2.18 requires pandas>=1.3.0, but you have pandas 1.2.4 which is incompatible.\n","yfinance 0.2.18 requires requests>=2.26, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed d2l-0.17.6 matplotlib-3.5.1 numpy-1.21.5 pandas-1.2.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["d2l","matplotlib","mpl_toolkits","numpy"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow\n","  Using cached tensorflow-2.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (585.9 MB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.54.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.8)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.0)\n","Collecting numpy<1.24,>=1.22 (from tensorflow)\n","  Using cached numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.2)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.10.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.25.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2022.12.7)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.2)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n","Installing collected packages: numpy, tensorflow\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.5\n","    Uninstalling numpy-1.21.5:\n","      Successfully uninstalled numpy-1.21.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","arviz 0.15.1 requires pandas>=1.3.0, but you have pandas 1.2.4 which is incompatible.\n","d2l 0.17.6 requires numpy==1.21.5, but you have numpy 1.23.5 which is incompatible.\n","mizani 0.8.1 requires pandas>=1.3.5, but you have pandas 1.2.4 which is incompatible.\n","plotnine 0.10.1 requires pandas>=1.3.5, but you have pandas 1.2.4 which is incompatible.\n","xarray 2022.12.0 requires pandas>=1.3, but you have pandas 1.2.4 which is incompatible.\n","yfinance 0.2.18 requires pandas>=1.3.0, but you have pandas 1.2.4 which is incompatible.\n","yfinance 0.2.18 requires requests>=2.26, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.23.5 tensorflow-2.12.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","tensorflow"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas==1.3.5\n","  Using cached pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (1.23.5)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7.3->pandas==1.3.5) (1.16.0)\n","Installing collected packages: pandas\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.2.4\n","    Uninstalling pandas-1.2.4:\n","      Successfully uninstalled pandas-1.2.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","d2l 0.17.6 requires numpy==1.21.5, but you have numpy 1.23.5 which is incompatible.\n","d2l 0.17.6 requires pandas==1.2.4, but you have pandas 1.3.5 which is incompatible.\n","google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 1.3.5 which is incompatible.\n","google-colab 1.0.0 requires requests>=2.27.0, but you have requests 2.25.1 which is incompatible.\n","yfinance 0.2.18 requires requests>=2.26, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed pandas-1.3.5\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.5.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]}]},{"cell_type":"code","source":["import time\n","import numpy as np\n","import inspect\n","import collections\n","from IPython import display\n","import tensorflow as tf\n","\n","def add_to_class(Class):\n","    \"\"\"Register functions as methods in created class.\"\"\"\n","    def wrapper(obj):\n","        setattr(Class, obj.__name__, obj)\n","    return wrapper\n","\n","class HyperParameters:\n","    \"\"\"The base class of hyperparameters.\"\"\"\n","    def save_hyperparameters(self, ignore=[]):\n","        frame = inspect.currentframe().f_back\n","        _, _, _, local_vars = inspect.getargvalues(frame)\n","        self.hparams = {k:v for k, v in local_vars.items()\n","                        if k not in set(ignore+['self']) and not k.startswith('_')}\n","        for k, v in self.hparams.items():\n","            setattr(self, k, v)"],"metadata":{"id":"M5W1KhEAvvRv","executionInfo":{"status":"ok","timestamp":1683887594356,"user_tz":-540,"elapsed":1,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":277,"outputs":[]},{"cell_type":"code","source":["class ProgressBoard(HyperParameters):\n","    \"\"\"The board that plots data points in animation.\"\"\"\n","    def __init__(self, xlabel=None, ylabel=None, xlim=None,\n","                 ylim=None, xscale='linear', yscale='linear',\n","                 ls=['-', '--', '-.', ':'], colors=['C0', 'C1', 'C2', 'C3'],\n","                 fig=None, axes=None, figsize=(3.5, 2.5), display=True):\n","        self.save_hyperparameters()\n","\n","    def draw(self, x, y, label, every_n=1):\n","        Point = collections.namedtuple('Point', ['x', 'y'])\n","        if not hasattr(self, 'raw_points'):\n","            self.raw_points = collections.OrderedDict()\n","            self.data = collections.OrderedDict()\n","        if label not in self.raw_points:\n","            self.raw_points[label] = []\n","            self.data[label] = []\n","        points = self.raw_points[label]\n","        line = self.data[label]\n","        points.append(Point(x, y))\n","        if len(points) != every_n:\n","            return\n","        mean = lambda x: sum(x) / len(x)\n","        line.append(Point(mean([p.x for p in points]),\n","                          mean([p.y for p in points])))\n","        points.clear()\n","        if not self.display:\n","            return\n","        d2l.use_svg_display()\n","        if self.fig is None:\n","            self.fig = d2l.plt.figure(figsize=self.figsize)\n","        plt_lines, labels = [], []\n","        for (k, v), ls, color in zip(self.data.items(), self.ls, self.colors):\n","            plt_lines.append(d2l.plt.plot([p.x for p in v], [p.y for p in v],\n","                                          linestyle=ls, color=color)[0])\n","            labels.append(k)\n","        axes = self.axes if self.axes else d2l.plt.gca()\n","        if self.xlim: axes.set_xlim(self.xlim)\n","        if self.ylim: axes.set_ylim(self.ylim)\n","        if not self.xlabel: self.xlabel = self.x\n","        axes.set_xlabel(self.xlabel)\n","        axes.set_ylabel(self.ylabel)\n","        axes.set_xscale(self.xscale)\n","        axes.set_yscale(self.yscale)\n","        axes.legend(plt_lines, labels)\n","        display.display(self.fig)\n","        display.clear_output(wait=True)"],"metadata":{"id":"bHIPhVt7XHKf","executionInfo":{"status":"ok","timestamp":1683887595265,"user_tz":-540,"elapsed":5,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":278,"outputs":[]},{"cell_type":"code","source":["class Module(tf.keras.Model, HyperParameters):\n","    \"\"\"The base class of models.\"\"\"\n","    def __init__(self, plot_train_per_epoch=2, plot_valid_per_epoch=1):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.board = ProgressBoard()\n","        self.training = None\n","\n","    def loss(self, y_hat, y):\n","        return cross_entropy(y_hat, y)\n","\n","    def forward(self, X):\n","        assert hasattr(self, 'net'), 'Neural network is defined'\n","        return self.net(X)\n","\n","    def call(self, X, *args, **kwargs):\n","        if kwargs and \"training\" in kwargs:\n","            self.training = kwargs['training']\n","        return self.forward(X, *args)\n","\n","    def plot(self, key, value, train):\n","        \"\"\"Plot a point in animation.\"\"\"\n","        assert hasattr(self, 'trainer'), 'Trainer is not inited'\n","        self.board.xlabel = 'epoch'\n","        if train:\n","            x = self.trainer.train_batch_idx / \\\n","                self.trainer.num_train_batches\n","            n = self.trainer.num_train_batches / \\\n","                self.plot_train_per_epoch\n","        else:\n","            x = self.trainer.epoch + 1\n","            n = self.trainer.num_val_batches / \\\n","                self.plot_valid_per_epoch\n","        self.board.draw(x, value.numpy(), (\n","            'train_' if train else 'val_') + key, every_n=int(n))\n","    def training_step(self, batch):\n","        l = self.loss(self(*batch[:-1]), batch[-1])\n","        self.plot('loss', l, train=True)\n","        return l\n","\n","    def validation_step(self, batch):\n","        l = self.loss(self(*batch[:-1]), batch[-1])\n","        self.plot('loss', l, train=False)\n","\n","    def configure_optimizers(self):\n","        raise NotImplementedError\n","\n","class DataModule(HyperParameters):\n","    \"\"\"The base class of data.\"\"\"\n","    def __init__(self, root='../data'):\n","        self.save_hyperparameters()\n","\n","    def get_dataloader(self, train):\n","        raise NotImplemented\n","\n","    def train_dataloader(self):\n","        return self.get_dataloader(train=True)\n","\n","    def val_dataloader(self):\n","        return self.get_dataloader(train=False)\n","\n","class Trainer(HyperParameters):\n","    \"\"\"The base class for training models with data.\"\"\"\n","    def __init__(self, max_epochs, num_gpus=0, gradient_clip_val=0):\n","        self.save_hyperparameters()\n","        assert num_gpus == 0, 'No GPU support yet'\n","\n","    def prepare_data(self, data):\n","        self.train_dataloader = data.train_dataloader()\n","        self.val_dataloader = data.val_dataloader()\n","        self.num_train_batches = len(self.train_dataloader)\n","        self.num_val_batches = (len(self.val_dataloader)\n","                                if self.val_dataloader is not None else 0)\n","\n","    def prepare_model(self, model):\n","        model.trainer = self\n","        model.board.xlim = [0, self.max_epochs]\n","        self.model = model\n","\n","    def fit(self, model, data):\n","        self.save_hyperparameters()\n","        self.prepare_data(data)\n","        self.prepare_model(model)\n","        self.optim = model.configure_optimizers()\n","        self.epoch = 0\n","        self.train_batch_idx = 0\n","        self.val_batch_idx = 0\n","        for self.epoch in range(self.max_epochs):\n","            self.fit_epoch()\n","\n","    def fit_epoch(self):\n","        self.model.training = True\n","        for batch in self.train_dataloader:\n","            with tf.GradientTape() as tape:\n","                loss = self.model.training_step(self.prepare_batch(batch))\n","            grads = tape.gradient(loss, self.model.trainable_variables)\n","            if self.gradient_clip_val > 0:\n","                grads = self.clip_gradients(self.gradient_clip_val, grads)\n","            self.optim.apply_gradients(zip(grads, self.model.trainable_variables))\n","            self.train_batch_idx += 1\n","        if self.val_dataloader is None:\n","            return\n","        self.model.training = False\n","        for batch in self.val_dataloader:\n","            self.model.validation_step(self.prepare_batch(batch))\n","            self.val_batch_idx += 1\n","    def prepare_batch(self, batch):\n","        return batch"],"metadata":{"id":"uIkE0NVeYsax","executionInfo":{"status":"ok","timestamp":1683887595265,"user_tz":-540,"elapsed":5,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":279,"outputs":[]},{"cell_type":"code","source":["class Classifier(Module):\n","    \"\"\"The base class of classification models.\"\"\"\n","    def validation_step(self, batch):\n","        Y_hat = self(*batch[:-1])\n","        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n","        self.plot('acc', self.accuracy(Y_hat, batch[-1]), train=False)"],"metadata":{"id":"fLx1NexQE2-q","executionInfo":{"status":"ok","timestamp":1683887595266,"user_tz":-540,"elapsed":6,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":280,"outputs":[]},{"cell_type":"markdown","source":["## 7.1. **From Fully Connected Layers to Convolutions**"],"metadata":{"id":"PzIMgpH5LvN8"}},{"cell_type":"markdown","source":["#### 7.1.1. Invariance"],"metadata":{"id":"D6OhWxacLzld"}},{"cell_type":"markdown","source":["Object의 위치가 바뀌어도 똑같은 Class의 Object라고 인식해야 한다. 이걸 Translation Invariance라고 한다.\n","\n","Translation => 이동\n","\n","Invariance => 불변"],"metadata":{"id":"Y2mI3tY7L9QR"}},{"cell_type":"markdown","source":["#### 7.1.3. Convolutions"],"metadata":{"id":"l_jqd2WwMySh"}},{"cell_type":"markdown","source":["Convolution => 합성곱 => input X의 Translation이 일어나면 합성곱 안의 representation에서도 Translation이 일어남\n","\n","이는 X의 위치에 구애받지 않는다\n","\n","$[\\mathbf{H}]_{i, j} = u + \\sum_a\\sum_b [\\mathbf{V}]_{a, b}  [\\mathbf{X}]_{i+a, j+b}$\n","\n","실제 구현은 Kernel이 움직이면서 합성곱을 생성함으로써 위치에 구애받지 않게 된다."],"metadata":{"id":"33aQAj3LNMvZ"}},{"cell_type":"markdown","source":["2차원 텐서에 대한 Convolution\n","\n","$(f * g)(i, j) = \\sum_a\\sum_b f(a, b) g(i-a, j-b)$"],"metadata":{"id":"woRqJQQJN5WZ"}},{"cell_type":"markdown","source":["## 7.2. **Convolutions for Images**"],"metadata":{"id":"S1i3XFPGOBcq"}},{"cell_type":"code","source":["import tensorflow as tf"],"metadata":{"id":"FyQeDj_gOMOg","executionInfo":{"status":"ok","timestamp":1683887595266,"user_tz":-540,"elapsed":6,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":281,"outputs":[]},{"cell_type":"code","source":["def corr2d(X, K):\n","    \"\"\"Compute 2D cross-correlation.\"\"\"\n","    h, w = K.shape\n","    Y = tf.Variable(tf.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1)))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            Y[i, j].assign(tf.reduce_sum(\n","                X[i: i + h, j: j + w] * K))\n","    return Y"],"metadata":{"id":"XsndS0N6Ov5_","executionInfo":{"status":"ok","timestamp":1683887595266,"user_tz":-540,"elapsed":6,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":282,"outputs":[]},{"cell_type":"markdown","source":["Input과 Kernel을 가지고 Cross Correlation을 구하는 메소드이다."],"metadata":{"id":"S7TkG8L4O6X0"}},{"cell_type":"code","source":["X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","K = tf.constant([[0.0, 1.0], [2.0, 3.0]])\n","corr2d(X, K)"],"metadata":{"id":"6Dn6TUh3OyXh","executionInfo":{"status":"ok","timestamp":1683887595266,"user_tz":-540,"elapsed":5,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dd3ee797-ca6e-4f02-d1e7-084666278dd5"},"execution_count":283,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[19., 25.],\n","       [37., 43.]], dtype=float32)>"]},"metadata":{},"execution_count":283}]},{"cell_type":"markdown","source":["#### 7.2.2. Convolutional Layers"],"metadata":{"id":"8W6ZztTKPSaI"}},{"cell_type":"code","source":["class Conv2D(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def build(self, kernel_size):\n","        initializer = tf.random_normal_initializer()\n","        self.weight = self.add_weight(name='w', shape=kernel_size,\n","                                      initializer=initializer)\n","        self.bias = self.add_weight(name='b', shape=(1, ),\n","                                    initializer=initializer)\n","\n","    def call(self, inputs):\n","        return corr2d(inputs, self.weight) + self.bias"],"metadata":{"id":"wCYa4OjaPW9k","executionInfo":{"status":"ok","timestamp":1683887595266,"user_tz":-540,"elapsed":4,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":284,"outputs":[]},{"cell_type":"markdown","source":["Convolution Layer를 정의하였다. 기억 상 keras에도 따로 정의되어 있는 것으로 알고 있다."],"metadata":{"id":"_lXcpEydPb4s"}},{"cell_type":"markdown","source":["#### 7.2.3. Object Edge Detection in Images"],"metadata":{"id":"BxduheVaPhiK"}},{"cell_type":"code","source":["X = tf.Variable(tf.ones((6, 8)))\n","X[:, 2:6].assign(tf.zeros(X[:, 2:6].shape))\n","X"],"metadata":{"id":"HQd9dgKtPk2L","executionInfo":{"status":"ok","timestamp":1683887595266,"user_tz":-540,"elapsed":4,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"110fa353-4d74-46a8-ee8a-91a156615297"},"execution_count":285,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(6, 8) dtype=float32, numpy=\n","array([[1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.],\n","       [1., 1., 0., 0., 0., 0., 1., 1.]], dtype=float32)>"]},"metadata":{},"execution_count":285}]},{"cell_type":"code","source":["K = tf.constant([[1.0, -1.0]])"],"metadata":{"id":"f3FWkVaYPmtK","executionInfo":{"status":"ok","timestamp":1683887596763,"user_tz":-540,"elapsed":1500,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":286,"outputs":[]},{"cell_type":"code","source":["Y = corr2d(X, K)\n","Y"],"metadata":{"id":"a5dNspyXPpa7","executionInfo":{"status":"ok","timestamp":1683887596763,"user_tz":-540,"elapsed":31,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0db663bc-b7c2-4f84-864d-7cb334780622"},"execution_count":287,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(6, 7) dtype=float32, numpy=\n","array([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","       [ 0.,  1.,  0.,  0.,  0., -1.,  0.]], dtype=float32)>"]},"metadata":{},"execution_count":287}]},{"cell_type":"code","source":["corr2d(tf.transpose(X), K)"],"metadata":{"id":"TRXbieEtPuch","executionInfo":{"status":"ok","timestamp":1683887596763,"user_tz":-540,"elapsed":29,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3e6fcbcd-b2cc-4063-cd1a-f236796853bb"},"execution_count":288,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(8, 5) dtype=float32, numpy=\n","array([[0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0.]], dtype=float32)>"]},"metadata":{},"execution_count":288}]},{"cell_type":"markdown","source":["#### 7.2.4. Learning a Kernel"],"metadata":{"id":"3MlmlCBkPxLj"}},{"cell_type":"code","source":["# Construct a two-dimensional convolutional layer with 1 output channel and a\n","# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n","conv2d = tf.keras.layers.Conv2D(1, (1, 2), use_bias=False)\n","\n","# The two-dimensional convolutional layer uses four-dimensional input and\n","# output in the format of (example, height, width, channel), where the batch\n","# size (number of examples in the batch) and the number of channels are both 1\n","X = tf.reshape(X, (1, 6, 8, 1))\n","Y = tf.reshape(Y, (1, 6, 7, 1))\n","lr = 3e-2  # Learning rate\n","\n","Y_hat = conv2d(X)\n","for i in range(10):\n","    with tf.GradientTape(watch_accessed_variables=False) as g:\n","        g.watch(conv2d.weights[0])\n","        Y_hat = conv2d(X)\n","        l = (abs(Y_hat - Y)) ** 2\n","        # Update the kernel\n","        update = tf.multiply(lr, g.gradient(l, conv2d.weights[0]))\n","        weights = conv2d.get_weights()\n","        weights[0] = conv2d.weights[0] - update\n","        conv2d.set_weights(weights)\n","        if (i + 1) % 2 == 0:\n","            print(f'epoch {i + 1}, loss {tf.reduce_sum(l):.3f}')"],"metadata":{"id":"XGbC1LXSPzN8","executionInfo":{"status":"ok","timestamp":1683887596763,"user_tz":-540,"elapsed":28,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a6e0110-5676-461a-c2f4-88c88372f87a"},"execution_count":289,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 2, loss 33.890\n","epoch 4, loss 11.632\n","epoch 6, loss 4.387\n","epoch 8, loss 1.734\n","epoch 10, loss 0.699\n"]}]},{"cell_type":"code","source":["tf.reshape(conv2d.get_weights()[0], (1, 2))"],"metadata":{"id":"5q_eXF7AP29l","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":27,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d5fa733e-f840-49ae-ae82-ed39e1e3fb82"},"execution_count":290,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[ 0.89822  , -1.0700567]], dtype=float32)>"]},"metadata":{},"execution_count":290}]},{"cell_type":"markdown","source":["## 7.3. **Padding and Stride**\n"],"metadata":{"id":"du5P4H6sP_HN"}},{"cell_type":"markdown","source":["#### 7.3.1. Padding"],"metadata":{"id":"Qx2r5QmVQHqB"}},{"cell_type":"markdown","source":["Input과 Output의 차원이 같도록 Padding을 추가한다."],"metadata":{"id":"4Xc9gHbnQ4ow"}},{"cell_type":"code","source":["# We define a helper function to calculate convolutions. It initializes\n","# the convolutional layer weights and performs corresponding dimensionality\n","# elevations and reductions on the input and output\n","def comp_conv2d(conv2d, X):\n","    # (1, 1) indicates that batch size and the number of channels are both 1\n","    X = tf.reshape(X, (1, ) + X.shape + (1, ))\n","    Y = conv2d(X)\n","    # Strip the first two dimensions: examples and channels\n","    return tf.reshape(Y, Y.shape[1:3])\n","# 1 row and column is padded on either side, so a total of 2 rows or columns\n","# are added\n","conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same')\n","X = tf.random.uniform(shape=(8, 8))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"id":"UZlcRapHQUq0","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":26,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bc133eac-1e1b-405e-b4a9-4b8a81a611ee"},"execution_count":291,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([8, 8])"]},"metadata":{},"execution_count":291}]},{"cell_type":"code","source":["# We use a convolution kernel with height 5 and width 3. The padding on\n","# either side of the height and width are 2 and 1, respectively\n","conv2d = tf.keras.layers.Conv2D(1, kernel_size=(5, 3), padding='same')\n","comp_conv2d(conv2d, X).shape"],"metadata":{"id":"eqX9GowPQnrb","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":25,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0ebea28-bc83-4c89-a77f-11f458232ffb"},"execution_count":292,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([8, 8])"]},"metadata":{},"execution_count":292}]},{"cell_type":"markdown","source":["#### 7.3.2. Stride"],"metadata":{"id":"3Ol9WpeqQo1G"}},{"cell_type":"markdown","source":["Kernel이 움직일 때 얼만큼 움직일 것인가? 어떻게 움직여야 Input과 Output의 차원이 같아질까?"],"metadata":{"id":"4vUKMH9ERLsk"}},{"cell_type":"code","source":["conv2d = tf.keras.layers.Conv2D(1, kernel_size=3, padding='same', strides=2)\n","comp_conv2d(conv2d, X).shape"],"metadata":{"id":"WqBaCbBZRJYK","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":24,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9d4839ab-6e8b-45a6-b8f8-0486eace9945"},"execution_count":293,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([4, 4])"]},"metadata":{},"execution_count":293}]},{"cell_type":"code","source":["conv2d = tf.keras.layers.Conv2D(1, kernel_size=(3,5), padding='valid',\n","                                strides=(3, 4))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"id":"5xAZgdxaRUdO","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":22,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0dae5d9c-2a57-4990-ff95-a70a6cdeab43"},"execution_count":294,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([2, 1])"]},"metadata":{},"execution_count":294}]},{"cell_type":"markdown","source":["## 7.4. **Multiple Input and Multiple Output Channels**"],"metadata":{"id":"SLgU2-oZRZDG"}},{"cell_type":"markdown","source":["사진 파일은 대개 RGB, 이렇게 채널이 여러 개 있다. 채널마다의 Kernel을 부여해서 각각 Convolution을 구한 후 더하면 Multiple Channel에 대해 Handling할 수 있다."],"metadata":{"id":"YILapmwxReev"}},{"cell_type":"markdown","source":["#### 7.4.1. Multiple Input Channels"],"metadata":{"id":"QdLPI2F3SHjO"}},{"cell_type":"code","source":["def corr2d_multi_in(X, K):\n","    # Iterate through the 0th dimension (channel) of K first, then add them up\n","    return tf.reduce_sum([corr2d(x, k) for x, k in zip(X, K)], axis=0)"],"metadata":{"id":"ReP809lAR4jj","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":21,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":295,"outputs":[]},{"cell_type":"code","source":["X = tf.constant([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n","               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n","K = tf.constant([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n","\n","corr2d_multi_in(X, K)"],"metadata":{"id":"sbfsT-wCR6sc","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":21,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1f408a50-e56c-426f-f373-d1d2318560b3"},"execution_count":296,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n","array([[ 56.,  72.],\n","       [104., 120.]], dtype=float32)>"]},"metadata":{},"execution_count":296}]},{"cell_type":"markdown","source":["2개의 채널을 가진 X에 대해 2개의 kernel로 구성된 K에 대해 Convolution을 진행한 결과이다."],"metadata":{"id":"AB5Z3TgwR9Tb"}},{"cell_type":"markdown","source":["#### 7.4.2. Multiple Output Channels"],"metadata":{"id":"WDjH8b_ESD7d"}},{"cell_type":"code","source":["def corr2d_multi_in_out(X, K):\n","    # Iterate through the 0th dimension of K, and each time, perform\n","    # cross-correlation operations with input X. All of the results are\n","    # stacked together\n","    return tf.stack([corr2d_multi_in(X, k) for k in K], 0)"],"metadata":{"id":"uTxyB8PmSMac","executionInfo":{"status":"ok","timestamp":1683887596764,"user_tz":-540,"elapsed":20,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":297,"outputs":[]},{"cell_type":"markdown","source":["7.4.1절에서 잘 보면 더하기 전에 채널마다 Output이 나오는 것을 확인할 수 있다. 따라서 reduce_sum을 빼면 Multiple output을 구현할 수 있다."],"metadata":{"id":"EQKjFwDtSOMZ"}},{"cell_type":"code","source":["K = tf.stack((K, K + 1, K + 2), 0)\n","K.shape"],"metadata":{"id":"MUaRxmdFSXCT","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":20,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccfae225-aca3-40ac-b530-c2a6498493fa"},"execution_count":298,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([3, 2, 2, 2])"]},"metadata":{},"execution_count":298}]},{"cell_type":"code","source":["corr2d_multi_in_out(X, K)"],"metadata":{"id":"MBg8_OapSdXy","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":19,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"91d52cb5-6fd2-4aa6-87da-059e91681fd0"},"execution_count":299,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(3, 2, 2), dtype=float32, numpy=\n","array([[[ 56.,  72.],\n","        [104., 120.]],\n","\n","       [[ 76., 100.],\n","        [148., 172.]],\n","\n","       [[ 96., 128.],\n","        [192., 224.]]], dtype=float32)>"]},"metadata":{},"execution_count":299}]},{"cell_type":"markdown","source":["#### 7.4.3. $1 \\times 1$ Convolutional Layer "],"metadata":{"id":"JjbX2jz2Sgsh"}},{"cell_type":"code","source":["def corr2d_multi_in_out_1x1(X, K):\n","    c_i, h, w = X.shape\n","    c_o = K.shape[0]\n","    X = tf.reshape(X, (c_i, h * w))\n","    K = tf.reshape(K, (c_o, c_i))\n","    # Matrix multiplication in the fully connected layer\n","    Y = tf.matmul(K, X)\n","    return tf.reshape(Y, (c_o, h, w))"],"metadata":{"id":"bhp8tA9zSpuk","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":18,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":300,"outputs":[]},{"cell_type":"code","source":["X = tf.random.normal((3, 3, 3), 0, 1)\n","K = tf.random.normal((2, 3, 1, 1), 0, 1)\n","Y1 = corr2d_multi_in_out_1x1(X, K)\n","Y2 = corr2d_multi_in_out(X, K)\n","assert float(tf.reduce_sum(tf.abs(Y1 - Y2))) < 1e-6"],"metadata":{"id":"WN0w139DSril","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":18,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":301,"outputs":[]},{"cell_type":"markdown","source":["## 7.5. **Pooling**"],"metadata":{"id":"yPEeznkmS9lS"}},{"cell_type":"markdown","source":["Kernel 없이 Window에 따라 값을 도출해냄\n","\n","![image.png](data:image/png;base64,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)"],"metadata":{"id":"XG5i4Yf0aux_"}},{"cell_type":"markdown","source":["$\\begin{split}\\max(0, 1, 3, 4)=4,\\\\\n","\\max(1, 2, 4, 5)=5,\\\\\n","\\max(3, 4, 6, 7)=7,\\\\\n","\\max(4, 5, 7, 8)=8.\\\\\\end{split}$"],"metadata":{"id":"jgOZQr3Ca8Mn"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","\n","def pool2d(X, pool_size, mode='max'):\n","    p_h, p_w = pool_size\n","    Y = tf.Variable(tf.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w +1)))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            if mode == 'max':\n","                Y[i, j].assign(tf.reduce_max(X[i: i + p_h, j: j + p_w]))\n","            elif mode =='avg':\n","                Y[i, j].assign(tf.reduce_mean(X[i: i + p_h, j: j + p_w]))\n","    return Y"],"metadata":{"id":"JqoSY71Xa6H9","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":18,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":302,"outputs":[]},{"cell_type":"code","source":["X = tf.constant([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","pool2d(X, (2, 2))"],"metadata":{"id":"y7dd67UzbAzK","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":17,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c9c257bd-373b-4048-e993-292b3eb05493"},"execution_count":303,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[4., 5.],\n","       [7., 8.]], dtype=float32)>"]},"metadata":{},"execution_count":303}]},{"cell_type":"code","source":["pool2d(X, (2, 2), 'avg')"],"metadata":{"id":"XAPPEczPbFmA","executionInfo":{"status":"ok","timestamp":1683887596765,"user_tz":-540,"elapsed":16,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"439e4fa1-3534-4643-d90e-4172a5b7f87f"},"execution_count":304,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n","array([[2., 3.],\n","       [5., 6.]], dtype=float32)>"]},"metadata":{},"execution_count":304}]},{"cell_type":"markdown","source":["Window의 최댓값을 리턴하는 Max-Pooling, Window의 평균값을 리턴하는 Avg-Pooling이 있다."],"metadata":{"id":"jZjIOoHfbPB6"}},{"cell_type":"markdown","source":["#### 7.5.2. Padding and Stride"],"metadata":{"id":"7BbrAKFabYVw"}},{"cell_type":"markdown","source":["Convolution의 그것과 유사하게 원하는 output 모양을 만들기 위해 Padding을 추가한다.\n","\n","Keras에 Pooling 역시 구현이 되어있다."],"metadata":{"id":"wUyWpw9zbbrh"}},{"cell_type":"code","source":["X = tf.reshape(tf.range(16, dtype=tf.float32), (1, 4, 4, 1))\n","X"],"metadata":{"id":"EP6YEqBQbbEY","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":15,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bae23080-aa10-4811-9043-8e5b1bb22752"},"execution_count":305,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 4, 4, 1), dtype=float32, numpy=\n","array([[[[ 0.],\n","         [ 1.],\n","         [ 2.],\n","         [ 3.]],\n","\n","        [[ 4.],\n","         [ 5.],\n","         [ 6.],\n","         [ 7.]],\n","\n","        [[ 8.],\n","         [ 9.],\n","         [10.],\n","         [11.]],\n","\n","        [[12.],\n","         [13.],\n","         [14.],\n","         [15.]]]], dtype=float32)>"]},"metadata":{},"execution_count":305}]},{"cell_type":"code","source":["pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3])\n","# Pooling has no model parameters, hence it needs no initialization\n","pool2d(X)"],"metadata":{"id":"Pi8Cb6Vhbgsp","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":13,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"56157de0-2d40-4b35-b988-a98e74255842"},"execution_count":306,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[10.]]]], dtype=float32)>"]},"metadata":{},"execution_count":306}]},{"cell_type":"code","source":["paddings = tf.constant([[0, 0], [1,0], [1,0], [0,0]])\n","X_Padded = X\n","pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='valid',\n","                                   strides=2)\n","pool2d(X_Padded)"],"metadata":{"id":"iDktxTscbmNv","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":12,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b314ca6a-df3c-4654-bc05-24aba947065f"},"execution_count":307,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1, 1, 1), dtype=float32, numpy=array([[[[10.]]]], dtype=float32)>"]},"metadata":{},"execution_count":307}]},{"cell_type":"markdown","source":["#### 7.5.3. Multiple Channels"],"metadata":{"id":"7c_5MCVkbyTu"}},{"cell_type":"markdown","source":["TF Framework는 Channel 개수가 차원의 마지막 축에 해당한다.\n","\n","Multiple Channels역시 Convolution의 그것과 유사하다."],"metadata":{"id":"HdClJAZzb_Tw"}},{"cell_type":"code","source":["# Concatenate along `dim=3` due to channels-last syntax\n","X = tf.concat([X, X + 1], 3)\n","X"],"metadata":{"id":"RaAJf4rNb2BC","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":10,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9c0c8a9-7f96-4c3e-d967-9f709f116afd"},"execution_count":308,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 4, 4, 2), dtype=float32, numpy=\n","array([[[[ 0.,  1.],\n","         [ 1.,  2.],\n","         [ 2.,  3.],\n","         [ 3.,  4.]],\n","\n","        [[ 4.,  5.],\n","         [ 5.,  6.],\n","         [ 6.,  7.],\n","         [ 7.,  8.]],\n","\n","        [[ 8.,  9.],\n","         [ 9., 10.],\n","         [10., 11.],\n","         [11., 12.]],\n","\n","        [[12., 13.],\n","         [13., 14.],\n","         [14., 15.],\n","         [15., 16.]]]], dtype=float32)>"]},"metadata":{},"execution_count":308}]},{"cell_type":"code","source":["paddings = tf.constant([[0, 0], [1,0], [1,0], [0,0]])\n","X_padded = tf.pad(X, paddings, \"CONSTANT\")\n","pool2d = tf.keras.layers.MaxPool2D(pool_size=[3, 3], padding='valid',\n","                                   strides=2)\n","pool2d(X_padded)"],"metadata":{"id":"giMyUtz3b9TU","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":9,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"387592c9-dd77-4f08-9ec3-580da894f6a2"},"execution_count":309,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 2, 2, 2), dtype=float32, numpy=\n","array([[[[ 5.,  6.],\n","         [ 7.,  8.]],\n","\n","        [[13., 14.],\n","         [15., 16.]]]], dtype=float32)>"]},"metadata":{},"execution_count":309}]},{"cell_type":"markdown","source":["## 7.6. **Convolutional Neural Networks (LeNet)**"],"metadata":{"id":"tyc9FQRBgVGZ"}},{"cell_type":"markdown","source":["LeNet, 그 중 LeNet-5는 Convolution-Pooling Layer 두개가 있는 레이어 파트와, Dense 세 개가 있는 레이어 파트로 구성된다.\n","\n","Convolution Layer는 Convolution-Sigmoid-Pooling 으로 이루어진다.\n","LeNet은 28*28 필기체 숫자 이미지를 숫자 당 약 1%의 오차율로 예측한다고 한다."],"metadata":{"id":"gXg5M8PRgbNA"}},{"cell_type":"code","source":["class LeNet(Classifier):\n","    \"\"\"The LeNet-5 model.\"\"\"\n","    def __init__(self, lr=0.1, num_classes=10):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.net = tf.keras.models.Sequential([\n","            tf.keras.layers.Conv2D(filters=6, kernel_size=5,\n","                                   activation='sigmoid', padding='same'),\n","            tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n","            tf.keras.layers.Conv2D(filters=16, kernel_size=5,\n","                                   activation='sigmoid'),\n","            tf.keras.layers.AvgPool2D(pool_size=2, strides=2),\n","            tf.keras.layers.Flatten(),\n","            tf.keras.layers.Dense(120, activation='sigmoid'),\n","            tf.keras.layers.Dense(84, activation='sigmoid'),\n","            tf.keras.layers.Dense(num_classes)])"],"metadata":{"id":"7DPGMAlUg4IX","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":8,"user":{"displayName":"이찬영","userId":"09288134256739852277"}}},"execution_count":310,"outputs":[]},{"cell_type":"code","source":["@add_to_class(Classifier)\n","def layer_summary(self, X_shape):\n","    X = tf.random.normal(X_shape)\n","    for layer in self.net.layers:\n","        X = layer(X)\n","        print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n","\n","model = LeNet()\n","model.layer_summary((1, 28, 28, 1))"],"metadata":{"id":"OB3-JLsVhnvu","executionInfo":{"status":"ok","timestamp":1683887596766,"user_tz":-540,"elapsed":8,"user":{"displayName":"이찬영","userId":"09288134256739852277"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"87af6f33-6f9b-4ebc-bafa-e496c1ee05d1"},"execution_count":311,"outputs":[{"output_type":"stream","name":"stdout","text":["Conv2D output shape:\t (1, 28, 28, 6)\n","AveragePooling2D output shape:\t (1, 14, 14, 6)\n","Conv2D output shape:\t (1, 10, 10, 16)\n","AveragePooling2D output shape:\t (1, 5, 5, 16)\n","Flatten output shape:\t (1, 400)\n","Dense output shape:\t (1, 120)\n","Dense output shape:\t (1, 84)\n","Dense output shape:\t (1, 10)\n"]}]}]}